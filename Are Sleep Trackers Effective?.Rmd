---
title: "Are Sleep Trackers Effective?"
author: "Ashley Shang "
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
  html_document: 
    theme: cosmo
    toc: yes
  pdf_document: default
urlcolor: BrickRed
---

```{r, setup, include = FALSE}
knitr::opts_chunk$set(echo = FALSE, fig.align = 'center')
```

```{r, load-packages, include = FALSE}
library(readr)
library(rsample)
library(caret)
library(rpart)
library(knitr)
library(kableExtra)
library(ggplot2)
library(gridExtra)
library(tibble)
```

***

# Abstract

 > Personal sleep tracking devices are becoming more and more popular. Statistical learning techniques are used to determine if it is possible to effectively predict time asleep from data that would be available without the aid of a sleep tracker.

***

# Introduction

It is without question that sleep is a very important process for both learning and memory. [^1] For optimal learning, sleep, both in quality and quantity, is required before and after learning. Depending on certain demographic factors, there are different sleep prescriptions, but for adults, a minimum of seven hours is needed to avoid impairment. [^2] Recently, the link between shift work and cancer has been well established. While more study is needed, there seems to be growing evidence that lack of sleep may play a strong causal role in many cancers. [^3] As the public has become more aware of the importance of sleep, the use of "smart" devices to track sleep has risen. Many sleep trackers provide a wealth of information including not only time asleep, but also details such as time spent in the various stages of sleep. (Light, deep, REM.)

The effectiveness of these sleep devices is still in question. [^4] While the breadth of data that they make available is interesting, the most important by far is the total time asleep. (Asleep being defined clinically, not by simply being in bed.) The additional data, such as time in REM sleep, is interesting, however it is unclear what the target values should be, and more importantly, how we could affect change in these numbers. In contrast, there is a wealth of advice on how to increase quality and time spent asleep. [^5] If total time asleep is the only data worth tracking, is a smart device actually necessary? Is it possible to estimate time asleep based on simple metrics such as time spent in bed?

Statistical learning techniques were applied to a four month sample of data from a Fitbit [^6] user. Time spent in bed was used to predict total time asleep. The results indicate that this prediction can be made with a reasonably small amount of error. However, practical and statistical limitations suggest the need for further investigation.

***

# Methods

## Data

The data was accessed via the data export tool provided by Fitbit. [^7] It was collected using a Fitbit Versa 2 by a single subject, a 32 year old adult male living in Ohio and working as a professor. The Fitbit Versa 2 uses both motion and heart rate variability [^8] to predict when the user is sleeping. The collection dates were a series of consecutive days in autumn of 2018. The two quantities of interest in the data are the time spent asleep and the time spent in bed each time the user sleeps. (A user could sleep more than once a day. For example, a two hour nap in the afternoon.) If the former can be predicted from the latter, the device seems unnecessary. (Time spent in bed could simply be tracked manually by a user. Although, it should be noted that one of the benefits of the devices is the automatic tracking of this quantity, which is probably more accurate than manual human tracking.)

```{r, load-data, message = FALSE}
sleep = read_csv(file = "data/fitbit-export-20190904.csv")
```

```{r, split-data}
sleep_trn = head(sleep, n = 100)
sleep_tst = tail(sleep, n = 22)

sleep_est = head(sleep_trn, n = 80)
sleep_val = tail(sleep_trn, n = 20)
```

## Modeling

In order to predict time asleep given time in bed, three modeling techniques were considered: linear models, k-nearest neighbors models, and tree models. No transformations were considered with the linear model. Default tuning parameters were used to train the two non-parametric models. Only time in bed was used as a predictor variable.

```{r}
lm_mod = lm(min_asleep ~ time_bed, data = sleep_est)
knn_mod = knnreg(min_asleep ~ time_bed, data = sleep_est)
tree_mod = rpart(min_asleep ~ time_bed, data = sleep_est)
```

## Evaluation

To evaluate the ability to predict time asleep with these models, the data was split into estimation, validation, and testing sets. Because of the dependence structure of the data, that is the consecutive nature of the days, the data was split chronologically. That is, the test set is the last 20% of the data chronologically. (And similarly for the validation data.) This is done to evaluate the ability to predict future nights of sleep from past data. Error metrics and graphics are reported using the validation data in the Results section.

***

# Results

```{r, calc-rmse}
calc_rmse = function(actual, predicted) {
  sqrt(mean( (actual - predicted) ^ 2) )
}
```

```{r, calc-validation-error}
sleep_val_rmse = c(calc_rmse(actual = sleep_val$min_asleep,
                             predicted = predict(lm_mod, sleep_val)),
                   calc_rmse(actual = sleep_val$min_asleep,
                             predicted = predict(knn_mod, sleep_val)),
                   calc_rmse(actual = sleep_val$min_asleep,
                             predicted = predict(tree_mod, sleep_val)))
```

```{r, numeric-results}
sleep_results = tibble(c("Linear", "KNN", "Tree"), sleep_val_rmse)
names(sleep_results) = c("models", "validation RMSE")
kable(sleep_results, format = "html") %>% #can input digits = n
  kable_styling(bootstrap_options = c("striped"), full_width = FALSE)
```

```{r, graphical-results, fig.height = 4, fig.width = 12}
pre_lm_val = predict(lm_mod, newdata = sleep_val)
pre_knn_val = predict(knn_mod, newdata = sleep_val)
pre_tree_val = predict(tree_mod, newdata = sleep_val)
x_upper = max(pre_lm_val, pre_knn_val, pre_tree_val) 
x_lower = min(pre_lm_val, pre_knn_val, pre_tree_val)
#lims = c(300,500) <- square area
par(mfrow = c(1, 3))
plot(x = pre_lm_val, y = sleep_val$min_asleep, 
     col = "red", xlim = c(x_lower, x_upper),
     ylim = c(min(sleep_val$min_asleep), 
              max(sleep_val$min_asleep)),
     xlab = "linear model prediction", 
     ylab = "actual value",
     main = "title")
abline(0,1)
grid()
plot(x = pre_knn_val, y = sleep_val$min_asleep, 
     col = "blue",  xlim = c(x_lower, x_upper),
     ylim = c(min(sleep_val$min_asleep), 
              max(sleep_val$min_asleep)),
     xlab = "k-nearest neighbors model prediction", 
     ylab = "actual value")
abline(0,1)
grid()
plot(x = pre_tree_val, y = sleep_val$min_asleep, 
     col = "green",  xlim = c(x_lower, x_upper),
     ylim = c(min(sleep_val$min_asleep), 
              max(sleep_val$min_asleep)),
     xlab = "tree model prediction", 
     ylab = "actual value")
abline(0,1)
grid()
```

***

# Discussion

```{r, test-rmse}
RMSE(sleep_tst$min_asleep, predict(lm(min_asleep ~ time_bed, data = sleep_trn), newdata = sleep_tst))
```

From the plots we can see that both linear model and k-nearest neighbors model show an apparent linear relation between the actual values and the predictions, that is, these models got good performance over the validation set. According the validation RMSE, the linear model is supposed to have better performance than the knn model, even though it is not conspicuous in the graphics. The $R^2$ of the linear model is up to 0.979, which is a great number, and that means the total sleep time does have strong linear correlation with the time in bed. But on the other hand, the models only took the time element in account, which obviously would have correlation, more or less. For example, one may have a long time in bed, and most time he/she may be asleep, but he/she might wake often, even though every awake period may be short, it does not mean he/she had a good sleep quality. Besides, the sleep degree (deep/light) also could be included into the future analysis about the sleep quality. 

In addition, by fitting the model on the estimation data set and calculating the training RMSE, solid outcome could be gained that linear model still is “the best”, its test RMSE as above. It is a quite good outcome, however, the training RMSE has a lower value than the test RMSE. It seems that because of the small amount of data, **overfitting** occurs, in the performance of better fitting on the training data but poorer predicting on the test data. To choose an appropriate model more accurately, more data should be involved in training, and it is better to use differernt partitions to perform multiple rounds of cross-validation in order to test model's ability to predict new data rather than to estimate it.  


***

# Appendix

## Data Dictionary

- `start_time` - The date and time which the device detected the user has gone to bed due to lack of motion. (But not necessarily started sleep.)
- `end_time` - The date and time which the device detected that the user is no longer in bed, due to motion.
- `min_asleep` - The total sleep time, in minutes. This is meant to estimate a clinical measure of sleep. (Not simply time in bed.)
- `min_awake` - The time spent in bed, but awake, in minutes.
- `num_awake` - The number of times the user "awoke" during their time in bed.
- `time_bed` - Duration between `start_time` and `end_time`. The sum of `min_asleep` and `min_awake`. In other words, total time in bed, in minutes.
- `min_rem` - Total time spent in REM sleep, in minutes.
- `min_light` - Total time spent in light sleep, in minutes.
- `min_deep` - Total time spent in deep sleep, in minutes.

## EDA

```{r, eda-plots, fig.height = 4, fig.width = 12}
plot_1 = sleep_trn %>% 
  ggplot(aes(x = min_asleep)) + 
  geom_histogram(bins = 30)

plot_2 = sleep_trn %>% 
  ggplot(aes(x = time_bed)) + 
  geom_histogram(bins = 30)

plot_3 = sleep_trn %>% 
  ggplot(aes(x = time_bed, y = min_asleep)) + 
  geom_point()

grid.arrange(plot_1, plot_2, plot_3, ncol = 3)
```

[^1]: [Harvard Medicine: Sleep, Learning, and Memory](http://healthysleep.med.harvard.edu/healthy/matters/benefits-of-sleep/learning-memory)
[^2]: [CDC: How Much Sleep Do I Need?](https://www.cdc.gov/sleep/about_sleep/how_much_sleep.html)
[^3]: [Shift Work and Cancer, The Evidence and the Challenge](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2954516/)
[^4]: [Consumer sleep tracking devices: a review of mechanisms, validity and utility](https://www.tandfonline.com/doi/abs/10.1586/17434440.2016.1171708)
[^5]: [Everything you need to know about sleep, but are too tired to ask](https://news.berkeley.edu/2017/10/17/whywesleep/)
[^6]: [Wikipedia: Fitbit](https://en.wikipedia.org/wiki/Fitbit)
[^7]: The author would like to note that Fitbit makes it incredibly difficult for users to obtain their own data.
[^8]: [Wikipedia: Heart rate variability](https://en.m.wikipedia.org/wiki/Heart_rate_variability)

```{r, this-is-bad-code, include = FALSE}
# what is divisible by 3?
A_VARIABLE = 1:100
ifelse(A_VARIABLE %% 3 == 1, "Yes", "No")

# how long are character strings?
another_variable = c("hello", "STAT", "432")
for (i in seq_along(another_variable)) {
  print(nchar(another_variable[i]))
}

# just some vectors
x = 1:100
y = 5:6
z = x ^ 2 + y ^ 2

# an if-else statement
if (1 > 100) {
  print("HELLO!")
} else {
  print("GOODBYE")
}

# a simple linear model
FIT = lm(speed ~ dist, data = cars)
mean(FIT$residuals, na.rm = FALSE)
```
